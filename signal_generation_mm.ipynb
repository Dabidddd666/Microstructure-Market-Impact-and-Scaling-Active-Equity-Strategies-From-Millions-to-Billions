{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This module implements quantitative trading signals for the Alphathon competition\n",
    "# All signals are designed to be investable (no look-ahead bias) and reproducible\n",
    "\n",
    "import databento as db          \n",
    "import pandas as pd             \n",
    "import numpy as np             \n",
    "from datetime import datetime, timedelta  \n",
    "import warnings                \n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)  \n",
    "\n",
    "\n",
    "# Signal calculation parameters\n",
    "SIGNAL_WINDOWS = [20, 60, 120]  \n",
    "MIN_PERIODS_RATIO = 0.5\n",
    "\n",
    "print(\"Financial Signal Generation Module Initialized\")\n",
    "print(f\"Signal calculation windows: {SIGNAL_WINDOWS}\")\n",
    "print(\"All signals designed for investable implementation (no look-ahead bias)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd505027",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_parquet('/Users/david/Desktop/Alphathon/Data for Alphathon/20180501_20240101_agg_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ba301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>ts_event</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-02 00:00:00+00:00</td>\n",
       "      <td>65.63</td>\n",
       "      <td>66.34</td>\n",
       "      <td>65.49</td>\n",
       "      <td>66.24</td>\n",
       "      <td>803289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-03 00:00:00+00:00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>66.86</td>\n",
       "      <td>65.81</td>\n",
       "      <td>65.91</td>\n",
       "      <td>685405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-04 00:00:00+00:00</td>\n",
       "      <td>65.77</td>\n",
       "      <td>66.46</td>\n",
       "      <td>64.86</td>\n",
       "      <td>66.34</td>\n",
       "      <td>676332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-07 00:00:00+00:00</td>\n",
       "      <td>66.03</td>\n",
       "      <td>67.25</td>\n",
       "      <td>65.61</td>\n",
       "      <td>67.00</td>\n",
       "      <td>409636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-08 00:00:00+00:00</td>\n",
       "      <td>67.16</td>\n",
       "      <td>67.98</td>\n",
       "      <td>67.07</td>\n",
       "      <td>67.39</td>\n",
       "      <td>532910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792676</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023-12-22 00:00:00+00:00</td>\n",
       "      <td>196.00</td>\n",
       "      <td>197.00</td>\n",
       "      <td>193.88</td>\n",
       "      <td>194.66</td>\n",
       "      <td>1067697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792677</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023-12-26 00:00:00+00:00</td>\n",
       "      <td>195.32</td>\n",
       "      <td>195.81</td>\n",
       "      <td>192.78</td>\n",
       "      <td>194.98</td>\n",
       "      <td>700415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792678</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023-12-27 00:00:00+00:00</td>\n",
       "      <td>194.88</td>\n",
       "      <td>196.34</td>\n",
       "      <td>194.12</td>\n",
       "      <td>195.50</td>\n",
       "      <td>316032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792679</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023-12-28 00:00:00+00:00</td>\n",
       "      <td>195.41</td>\n",
       "      <td>197.01</td>\n",
       "      <td>194.75</td>\n",
       "      <td>196.90</td>\n",
       "      <td>337393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792680</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2023-12-29 00:00:00+00:00</td>\n",
       "      <td>197.62</td>\n",
       "      <td>198.61</td>\n",
       "      <td>196.56</td>\n",
       "      <td>197.16</td>\n",
       "      <td>333989.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792681 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       symbol                  ts_event    open    high     low   close  \\\n",
       "0           A 2018-05-02 00:00:00+00:00   65.63   66.34   65.49   66.24   \n",
       "1           A 2018-05-03 00:00:00+00:00   66.00   66.86   65.81   65.91   \n",
       "2           A 2018-05-04 00:00:00+00:00   65.77   66.46   64.86   66.34   \n",
       "3           A 2018-05-07 00:00:00+00:00   66.03   67.25   65.61   67.00   \n",
       "4           A 2018-05-08 00:00:00+00:00   67.16   67.98   67.07   67.39   \n",
       "...       ...                       ...     ...     ...     ...     ...   \n",
       "792676    ZTS 2023-12-22 00:00:00+00:00  196.00  197.00  193.88  194.66   \n",
       "792677    ZTS 2023-12-26 00:00:00+00:00  195.32  195.81  192.78  194.98   \n",
       "792678    ZTS 2023-12-27 00:00:00+00:00  194.88  196.34  194.12  195.50   \n",
       "792679    ZTS 2023-12-28 00:00:00+00:00  195.41  197.01  194.75  196.90   \n",
       "792680    ZTS 2023-12-29 00:00:00+00:00  197.62  198.61  196.56  197.16   \n",
       "\n",
       "           volume  \n",
       "0        803289.0  \n",
       "1        685405.0  \n",
       "2        676332.0  \n",
       "3        409636.0  \n",
       "4        532910.0  \n",
       "...           ...  \n",
       "792676  1067697.0  \n",
       "792677   700415.0  \n",
       "792678   316032.0  \n",
       "792679   337393.0  \n",
       "792680   333989.0  \n",
       "\n",
       "[792681 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_shifted = raw_data.copy()\n",
    "\n",
    "# IMPORTANT: Shift all OHLCV data by 1 period to avoid look-ahead bias\n",
    "# This ensures signals are only based on information available at market open\n",
    "print(\"Applying 1-period lag to OHLCV data to prevent look-ahead bias...\")\n",
    "raw_data_shifted[['open', 'high', 'low', 'close', 'volume']] = raw_data.groupby('symbol')[['open', 'high', 'low', 'close', 'volume']].shift(1)\n",
    "\n",
    "\n",
    "raw_data_shifted = raw_data_shifted.dropna(subset=['open', 'high', 'low', 'close', 'volume']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Data preprocessing complete!\")\n",
    "print(f\"Original shape: {raw_data.shape}\")\n",
    "print(f\"Processed shape: {raw_data_shifted.shape}\")\n",
    "print(f\"Rows removed due to lagging: {raw_data.shape[0] - raw_data_shifted.shape[0]}\")\n",
    "\n",
    "raw_data_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b653b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/rr869dkj11v2ndc3b68t2_2c0000gn/T/ipykernel_54379/1410477288.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result_df = result_df.groupby('symbol', group_keys=False).apply(calc_signal_group)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>ts_event</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>corwin_schultz_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-02 00:00:00+00:00</td>\n",
       "      <td>66.34</td>\n",
       "      <td>65.49</td>\n",
       "      <td>-0.073014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-03 00:00:00+00:00</td>\n",
       "      <td>66.86</td>\n",
       "      <td>65.81</td>\n",
       "      <td>-0.114370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-04 00:00:00+00:00</td>\n",
       "      <td>66.46</td>\n",
       "      <td>64.86</td>\n",
       "      <td>-0.135668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-07 00:00:00+00:00</td>\n",
       "      <td>67.25</td>\n",
       "      <td>65.61</td>\n",
       "      <td>-0.181303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-08 00:00:00+00:00</td>\n",
       "      <td>67.98</td>\n",
       "      <td>67.07</td>\n",
       "      <td>-0.052806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-09 00:00:00+00:00</td>\n",
       "      <td>67.44</td>\n",
       "      <td>66.94</td>\n",
       "      <td>-0.090921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-10 00:00:00+00:00</td>\n",
       "      <td>68.40</td>\n",
       "      <td>67.18</td>\n",
       "      <td>-0.115842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-11 00:00:00+00:00</td>\n",
       "      <td>68.87</td>\n",
       "      <td>68.12</td>\n",
       "      <td>-0.127469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-14 00:00:00+00:00</td>\n",
       "      <td>69.59</td>\n",
       "      <td>68.91</td>\n",
       "      <td>-0.067448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-05-15 00:00:00+00:00</td>\n",
       "      <td>70.44</td>\n",
       "      <td>69.00</td>\n",
       "      <td>-1.094210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                  ts_event   high    low  corwin_schultz_signal\n",
       "0      A 2018-05-02 00:00:00+00:00  66.34  65.49              -0.073014\n",
       "1      A 2018-05-03 00:00:00+00:00  66.86  65.81              -0.114370\n",
       "2      A 2018-05-04 00:00:00+00:00  66.46  64.86              -0.135668\n",
       "3      A 2018-05-07 00:00:00+00:00  67.25  65.61              -0.181303\n",
       "4      A 2018-05-08 00:00:00+00:00  67.98  67.07              -0.052806\n",
       "5      A 2018-05-09 00:00:00+00:00  67.44  66.94              -0.090921\n",
       "6      A 2018-05-10 00:00:00+00:00  68.40  67.18              -0.115842\n",
       "7      A 2018-05-11 00:00:00+00:00  68.87  68.12              -0.127469\n",
       "8      A 2018-05-14 00:00:00+00:00  69.59  68.91              -0.067448\n",
       "9      A 2018-05-15 00:00:00+00:00  70.44  69.00              -1.094210"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_corwin_schultz_signal(df):\n",
    "    \"\"\"\n",
    "    Calculate Corwin-Schultz high-low price spread signal\n",
    "    \n",
    "    Formula:\n",
    "    β_t = (ln(H_t/L_t))² + (ln(H_{t+1}/L_{t+1}))²\n",
    "    γ_t = (ln(max(H_t, H_{t+1})/min(L_t, L_{t+1})))²\n",
    "    S_t = 2(e^{α_t} - 1) / (1 + e^{α_t})\n",
    "    \n",
    "    where α_t is derived from β_t and γ_t\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create working copy to avoid modifying original data\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # CRITICAL: Sort by symbol and timestamp to ensure proper time series ordering\n",
    "    # This is essential for forward-looking calculations (t+1 references)\n",
    "    result_df = result_df.sort_values(['symbol', 'ts_event']).reset_index(drop=True)\n",
    "    \n",
    "    # Define nested function to calculate signals for each symbol group\n",
    "    def calc_signal_group(group):\n",
    "        \"\"\"\n",
    "        Calculate Corwin-Schultz signals for a single symbol group\n",
    "        \n",
    "        This function processes one symbol at a time to ensure proper\n",
    "        time series calculations without cross-contamination between stocks.\n",
    "        \"\"\"\n",
    "        group = group.copy()\n",
    "        \n",
    "        # ========================================================================\n",
    "        # STEP 1: Calculate β_t component\n",
    "        # β_t = (ln(H_t/L_t))² + (ln(H_{t+1}/L_{t+1}))²\n",
    "        # ========================================================================\n",
    "        \n",
    "        # Calculate squared log high-low ratios for current period\n",
    "        ln_hl_t = np.log(group['high'] / group['low']) ** 2\n",
    "        \n",
    "        # Get squared log high-low ratios for next period (forward-looking)\n",
    "        ln_hl_t_plus_1 = ln_hl_t.shift(-1)\n",
    "        \n",
    "        # Sum the two components to get β_t\n",
    "        beta_t = ln_hl_t + ln_hl_t_plus_1\n",
    "        \n",
    "        # Calculate γ_t = (ln(max(H_t, H_{t+1})/min(L_t, L_{t+1})))²\n",
    "        h_t = group['high']\n",
    "        h_t_plus_1 = group['high'].shift(-1)\n",
    "        l_t = group['low']\n",
    "        l_t_plus_1 = group['low'].shift(-1)\n",
    "        \n",
    "        max_h = np.maximum(h_t, h_t_plus_1)\n",
    "        min_l = np.minimum(l_t, l_t_plus_1)\n",
    "        gamma_t = (np.log(max_h / min_l)) ** 2\n",
    "        \n",
    "        # Calculate α_t (effective spread parameter)\n",
    "        # α_t = (√(2*β_t) - √(γ_t)) / (3 - 2*√2) - √(γ_t/(3 - 2*√2))\n",
    "        sqrt_2_beta = np.sqrt(2 * beta_t)\n",
    "        sqrt_gamma = np.sqrt(gamma_t)\n",
    "        denominator = 3 - 2 * np.sqrt(2)\n",
    "        \n",
    "        alpha_t = (sqrt_2_beta - sqrt_gamma) / denominator - sqrt_gamma / denominator\n",
    "        \n",
    "        # Calculate S_t = 2(e^{α_t} - 1) / (1 + e^{α_t})\n",
    "        exp_alpha = np.exp(alpha_t)\n",
    "        s_t = 2 * (exp_alpha - 1) / (1 + exp_alpha)\n",
    "        \n",
    "        group['beta_t'] = beta_t\n",
    "        group['gamma_t'] = gamma_t\n",
    "        group['alpha_t'] = alpha_t\n",
    "        group['corwin_schultz_signal'] = s_t\n",
    "        \n",
    "        return group\n",
    "    \n",
    "    # Apply calculation to each symbol group\n",
    "    result_df = result_df.groupby('symbol', group_keys=False).apply(calc_signal_group)\n",
    "    \n",
    "    # Remove rows with NaN values (last row of each symbol due to forward looking)\n",
    "    result_df = result_df.dropna(subset=['corwin_schultz_signal']).reset_index(drop=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Calculate the Corwin-Schultz signal\n",
    "data_with_signal = calculate_corwin_schultz_signal(raw_data_shifted)\n",
    "data_with_signal[['symbol', 'ts_event', 'high', 'low', 'corwin_schultz_signal']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1eafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_with_signal.to_parquet('/Users/david/Desktop/Alphathon/Data for Alphathon/corwin_schultz_signal.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0028352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Mean Reversion/Volatility signals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/rr869dkj11v2ndc3b68t2_2c0000gn/T/ipykernel_54489/2548992307.py:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result_df = result_df.groupby('symbol', group_keys=False).apply(calc_mr_signals_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Donchian Channel Breakout signals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/rr869dkj11v2ndc3b68t2_2c0000gn/T/ipykernel_54489/2548992307.py:80: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result_df = result_df.groupby('symbol', group_keys=False).apply(calc_donchian_signals_group)\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_reversion_signals(df, k_values=[20, 60, 120]):\n",
    "    \"\"\"\n",
    "    Calculate Mean Reversion/Volatility signals\n",
    "    \n",
    "    Formula:\n",
    "    z_MA^(k)(t) = (P_t - MA_k(P)_t) / stdev_k(P)_t\n",
    "    ΔEMA_t^(k) = EMA_t^(k) - EMA_{t-1}^(k)\n",
    "    \n",
    "    where k ∈ {20, 60, 120}\n",
    "    \"\"\"\n",
    "    \n",
    "    result_df = df.copy()\n",
    "    result_df = result_df.sort_values(['symbol', 'ts_event']).reset_index(drop=True)\n",
    "    \n",
    "    def calc_mr_signals_group(group):\n",
    "        group = group.copy()\n",
    "        price = group['close']  # Using close price as P_t\n",
    "        \n",
    "        for k in k_values:\n",
    "            # Calculate Moving Average\n",
    "            ma_k = price.rolling(window=k, min_periods=1).mean()\n",
    "            \n",
    "            # Calculate Rolling Standard Deviation\n",
    "            stdev_k = price.rolling(window=k, min_periods=1).std()\n",
    "            \n",
    "            # Calculate z-score signal: z_MA^(k)(t) = (P_t - MA_k(P)_t) / stdev_k(P)_t\n",
    "            z_ma_signal = (price - ma_k) / stdev_k\n",
    "            group[f'z_MA_{k}'] = z_ma_signal\n",
    "            \n",
    "            # Calculate EMA (Exponential Moving Average)\n",
    "            alpha = 2 / (k + 1)  # Standard EMA smoothing factor\n",
    "            ema_k = price.ewm(alpha=alpha, adjust=False).mean()\n",
    "            \n",
    "            # Calculate EMA difference: ΔEMA_t^(k) = EMA_t^(k) - EMA_{t-1}^(k)\n",
    "            delta_ema = ema_k.diff()\n",
    "            group[f'delta_EMA_{k}'] = delta_ema\n",
    "            \n",
    "        return group\n",
    "    \n",
    "    # Apply calculation to each symbol group\n",
    "    result_df = result_df.groupby('symbol', group_keys=False).apply(calc_mr_signals_group)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def calculate_donchian_breakout_signals(df, k_values=[20, 60, 120]):\n",
    "    \"\"\"\n",
    "    Calculate Donchian Channel Breakout signals\n",
    "    \n",
    "    Formula:\n",
    "    BRK_t^U = 1{C_t > max_{τ∈[t-k,t-1]} C_τ}\n",
    "    BRK_t^D = 1{C_t < min_{τ∈[t-k,t-1]} C_τ}\n",
    "    \n",
    "    where k ∈ {20, 60, 120}\n",
    "    \"\"\"\n",
    "    \n",
    "    result_df = df.copy()\n",
    "    result_df = result_df.sort_values(['symbol', 'ts_event']).reset_index(drop=True)\n",
    "    \n",
    "    def calc_donchian_signals_group(group):\n",
    "        group = group.copy()\n",
    "        price = group['close']  # Using close price as C_t\n",
    "        \n",
    "        for k in k_values:\n",
    "            # Calculate rolling max and min over [t-k, t-1] window\n",
    "            # We use shift(1) to exclude current period and look at previous k periods\n",
    "            rolling_max = price.shift(1).rolling(window=k, min_periods=1).max()\n",
    "            rolling_min = price.shift(1).rolling(window=k, min_periods=1).min()\n",
    "            \n",
    "            # Upper breakout: BRK_t^U = 1{C_t > max_{τ∈[t-k,t-1]} C_τ}\n",
    "            brk_upper = (price > rolling_max).astype(int)\n",
    "            group[f'BRK_U_{k}'] = brk_upper\n",
    "            \n",
    "            # Lower breakout: BRK_t^D = 1{C_t < min_{τ∈[t-k,t-1]} C_τ}\n",
    "            brk_lower = (price < rolling_min).astype(int)\n",
    "            group[f'BRK_D_{k}'] = brk_lower\n",
    "            \n",
    "        return group\n",
    "    \n",
    "    # Apply calculation to each symbol group\n",
    "    result_df = result_df.groupby('symbol', group_keys=False).apply(calc_donchian_signals_group)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Calculate Mean Reversion signals\n",
    "print(\"Calculating Mean Reversion/Volatility signals...\")\n",
    "data_with_mr = calculate_mean_reversion_signals(raw_data_shifted)\n",
    "\n",
    "# Calculate Donchian Breakout signals\n",
    "print(\"Calculating Donchian Channel Breakout signals...\")\n",
    "data_with_all_dc = calculate_donchian_breakout_signals(raw_data_shifted)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_with_mr.to_parquet('/Users/david/Desktop/Alphathon/signals/mean_reversion_signals.parquet')\n",
    "# data_with_all_dc.to_parquet('/Users/david/Desktop/Alphathon/signals/donchian_breakout_signals.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bb7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_low_volatility_beta_signals(df, k_values=[20, 60, 120]):\n",
    "    \"\"\"\n",
    "    Calculate Low Volatility/Low Beta signals\n",
    "    \n",
    "    Formula:\n",
    "    β_{i,t}^{(k)} = Cov_k(r_i, r_m)_t / Var_k(r_m)_t\n",
    "    \n",
    "    where:\n",
    "    - r_i is the return of stock i\n",
    "    - r_m is the market return (equal-weighted average of all stocks)\n",
    "    - k ∈ {20, 60, 120} is the rolling window\n",
    "    \"\"\"\n",
    "    \n",
    "    result_df = df.copy()\n",
    "    result_df = result_df.sort_values(['symbol', 'ts_event']).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate individual stock returns\n",
    "    result_df['return'] = result_df.groupby('symbol')['close'].pct_change()\n",
    "    \n",
    "    # Calculate market return (equal-weighted average of all stocks)\n",
    "    market_returns = result_df.groupby('ts_event')['return'].mean().reset_index()\n",
    "    market_returns.columns = ['ts_event', 'market_return']\n",
    "    \n",
    "    # Merge market returns back to the main dataframe\n",
    "    result_df = result_df.merge(market_returns, on='ts_event', how='left')\n",
    "    \n",
    "    def calc_beta_signals_group(group):\n",
    "        group = group.copy()\n",
    "        stock_returns = group['return']\n",
    "        market_returns = group['market_return']\n",
    "        \n",
    "        for k in k_values:\n",
    "            # Calculate rolling covariance between stock and market returns\n",
    "            cov_k = stock_returns.rolling(window=k, min_periods=max(1, k//2)).cov(market_returns)\n",
    "            \n",
    "            # Calculate rolling variance of market returns\n",
    "            var_k = market_returns.rolling(window=k, min_periods=max(1, k//2)).var()\n",
    "            \n",
    "            # Calculate beta: β_{i,t}^{(k)} = Cov_k(r_i, r_m)_t / Var_k(r_m)_t\n",
    "            beta_k = cov_k / var_k\n",
    "            \n",
    "            group[f'beta_{k}'] = beta_k\n",
    "            \n",
    "            # Also calculate rolling correlation for additional insight\n",
    "            corr_k = stock_returns.rolling(window=k, min_periods=max(1, k//2)).corr(market_returns)\n",
    "            group[f'correlation_{k}'] = corr_k\n",
    "            \n",
    "            # Calculate rolling volatility (standard deviation) of stock returns\n",
    "            vol_k = stock_returns.rolling(window=k, min_periods=max(1, k//2)).std()\n",
    "            group[f'volatility_{k}'] = vol_k\n",
    "        \n",
    "        return group\n",
    "    \n",
    "    # Apply calculation to each symbol group\n",
    "    result_df = result_df.groupby('symbol', group_keys=False).apply(calc_beta_signals_group)\n",
    "    \n",
    "    # Remove rows with NaN returns (first row of each symbol)\n",
    "    result_df = result_df.dropna(subset=['return']).reset_index(drop=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Calculate Low Volatility/Beta signals\n",
    "print(\"Calculating Low Volatility/Low Beta signals...\")\n",
    "data_with_beta = calculate_low_volatility_beta_signals(data_with_all_signals)\n",
    "\n",
    "print(\"Beta signal calculation complete!\")\n",
    "print(f\"Data shape: {data_with_beta.shape}\")\n",
    "\n",
    "# Show sample of beta signals\n",
    "beta_columns = [col for col in data_with_beta.columns if any(x in col for x in ['beta_', 'correlation_', 'volatility_'])]\n",
    "print(f\"\\nGenerated Beta-related columns: {beta_columns}\")\n",
    "\n",
    "# Display sample for one symbol\n",
    "sample_symbol = data_with_beta['symbol'].iloc[0]\n",
    "sample_data = data_with_beta[data_with_beta['symbol'] == sample_symbol].head(10)\n",
    "display_cols = ['symbol', 'ts_event', 'return', 'market_return'] + beta_columns[:6]\n",
    "sample_data[display_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a62c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all generated signals\n",
    "all_signal_columns = [col for col in data_with_beta.columns if any(x in col for x in \n",
    "                     ['z_MA_', 'delta_EMA_', 'BRK_U_', 'BRK_D_', 'beta_', 'correlation_', 'volatility_'])]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"COMPLETE SIGNAL SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "signal_categories = {\n",
    "    'Mean Reversion Z-Scores': [col for col in all_signal_columns if 'z_MA_' in col],\n",
    "    'EMA Momentum': [col for col in all_signal_columns if 'delta_EMA_' in col],\n",
    "    'Donchian Upper Breakouts': [col for col in all_signal_columns if 'BRK_U_' in col],\n",
    "    'Donchian Lower Breakouts': [col for col in all_signal_columns if 'BRK_D_' in col],\n",
    "    'Beta Coefficients': [col for col in all_signal_columns if 'beta_' in col],\n",
    "    'Market Correlations': [col for col in all_signal_columns if 'correlation_' in col],\n",
    "    'Rolling Volatilities': [col for col in all_signal_columns if 'volatility_' in col]\n",
    "}\n",
    "\n",
    "for category, signals in signal_categories.items():\n",
    "    print(f\"\\n{category}: {len(signals)} signals\")\n",
    "    for signal in signals:\n",
    "        print(f\"  - {signal}\")\n",
    "\n",
    "print(f\"\\nTotal signals generated: {len(all_signal_columns)}\")\n",
    "print(f\"Final dataset shape: {data_with_beta.shape}\")\n",
    "print(f\"Number of symbols: {data_with_beta['symbol'].nunique()}\")\n",
    "print(f\"Date range: {data_with_beta['ts_event'].min()} to {data_with_beta['ts_event'].max()}\")\n",
    "\n",
    "# Save the complete dataset\n",
    "output_path = '/Users/david/Desktop/Alphathon/Data for Alphathon/complete_signals_dataset.parquet'\n",
    "data_with_beta.to_parquet(output_path)\n",
    "print(f\"\\nDataset saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing OHLCV data from raw_data_shifted...\n",
      "Data shape - O: (647, 1426), H: (647, 1426), L: (647, 1426), C: (647, 1426), V: (647, 1426)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/rr869dkj11v2ndc3b68t2_2c0000gn/T/ipykernel_83910/922182478.py:10: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  out = series.pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Alpha Factors Generation (OHLCV-based factors) - Adapted for raw_data_shifted\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "# Utility functions\n",
    "def pct_change_safe(series: pd.Series) -> pd.Series:\n",
    "    out = series.pct_change()\n",
    "    return out.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def log_safe(series: pd.Series) -> pd.Series:\n",
    "    return np.log(series.replace(0, np.nan))\n",
    "\n",
    "# Prepare data from raw_data_shifted\n",
    "print(\"Preparing OHLCV data from raw_data_shifted...\")\n",
    "\n",
    "# Pivot data to get OHLCV as columns with symbols as index\n",
    "data_pivot = raw_data_shifted.set_index(['ts_event', 'symbol']).unstack('symbol')\n",
    "\n",
    "# Extract OHLCV dataframes\n",
    "O = data_pivot['open'].T\n",
    "H = data_pivot['high'].T  \n",
    "L = data_pivot['low'].T\n",
    "C = data_pivot['close'].T\n",
    "V = data_pivot['volume'].T\n",
    "\n",
    "print(f\"Data shape - O: {O.shape}, H: {H.shape}, L: {L.shape}, C: {C.shape}, V: {V.shape}\")\n",
    "\n",
    "# Base calculations\n",
    "ret_cc = pct_change_safe(C)\n",
    "dollarvol = C * V\n",
    "\n",
    "# True Range & ATR\n",
    "C_shift = C.shift(1)\n",
    "TR = pd.concat([\n",
    "    (H - L).abs(),\n",
    "    (H - C_shift).abs(),\n",
    "    (L - C_shift).abs()\n",
    "], axis=0).groupby(level=0).max()\n",
    "ATR14 = TR.rolling(14, min_periods=7).mean()\n",
    "\n",
    "# Alpha factors (10 factors)\n",
    "range_log = np.log(H.div(L)).replace([np.inf, -np.inf], np.nan)\n",
    "logV = log_safe(V)\n",
    "ADV60 = dollarvol.rolling(60, min_periods=20).mean()\n",
    "\n",
    "factors_raw = {\n",
    "    # No shift needed (available at market open)\n",
    "    \"alpha_overnight\": O.div(C.shift(1)) - 1,\n",
    "    \"alpha_gap_rev\": O.sub(C.shift(1)).div(C.shift(1)),\n",
    "    \n",
    "    # Shift needed (available after close)\n",
    "    \"alpha_intraday_rev\": C.sub(O).div(O),\n",
    "    \"alpha_rangevol_rev\": -0.5 * (range_log ** 2),\n",
    "    \"alpha_volsurprise\": (logV - logV.rolling(60, min_periods=20).mean()) / \n",
    "                        logV.rolling(60, min_periods=20).std(),\n",
    "    \"alpha_turnover_jump\": (dollarvol / ADV60).replace([np.inf, -np.inf], np.nan) - 1,\n",
    "    \"alpha_amihud_rev\": -(ret_cc.abs() / dollarvol.replace(0, np.nan)).replace([np.inf, -np.inf], np.nan)\n",
    "                       .rolling(20, min_periods=10).mean(),\n",
    "    \"alpha_clv\": ((C - L) - (H - C)) / (H - L).replace(0, np.nan),\n",
    "    \"alpha_st_trend_5_20\": (C.rolling(5, min_periods=3).mean() / \n",
    "                           C.rolling(20, min_periods=10).mean() - 1),\n",
    "    \"alpha_range_to_atr_rev\": -(range_log / ATR14.replace(0, np.nan)).replace([np.inf, -np.inf], np.nan),\n",
    "}\n",
    "\n",
    "# Factors requiring shift (available after close)\n",
    "NEED_SHIFT = {\n",
    "    \"alpha_intraday_rev\",\n",
    "    \"alpha_rangevol_rev\", \n",
    "    \"alpha_volsurprise\",\n",
    "    \"alpha_turnover_jump\",\n",
    "    \"alpha_amihud_rev\",\n",
    "    \"alpha_clv\",\n",
    "    \"alpha_st_trend_5_20\",\n",
    "    \"alpha_range_to_atr_rev\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_dataframes = []\n",
    "\n",
    "for name, df in factors_raw.items():\n",
    "    # Apply shift if needed for investable signals\n",
    "    investable = df.shift(1) if name in NEED_SHIFT else df\n",
    "    investable = investable.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Store for final dataframe\n",
    "    factor_dataframes.append(investable)\n",
    "\n",
    "# Create final dataframe with all alpha signals\n",
    "ohlcv_long = raw_data_shifted[['symbol', 'ts_event']].copy()\n",
    "\n",
    "# Add each alpha factor as a column\n",
    "for i, (name, _) in enumerate(factors_raw.items()):\n",
    "    factor_df = factor_dataframes[i]\n",
    "    \n",
    "    # Convert factor dataframe back to long format\n",
    "    factor_long = factor_df.stack().reset_index()\n",
    "    factor_long.columns = ['ts_event', 'symbol', name]\n",
    "    \n",
    "    # Merge with main dataframe\n",
    "    ohlcv_long = ohlcv_long.merge(factor_long, on=['symbol', 'ts_event'], how='left')\n",
    "\n",
    "# Create final signals dataframe\n",
    "final_signals_df = ohlcv_long.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d1190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
